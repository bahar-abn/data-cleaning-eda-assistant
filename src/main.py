"""
ÙØ§ÛŒÙ„ Ø§ØµÙ„ÛŒ Ù¾Ø±ÙˆÚ˜Ù‡
Ø§ÛŒÙ† Ù…Ø§Ú˜ÙˆÙ„ Ù…Ø³Ø¦ÙˆÙ„ Ø§Ø¬Ø±Ø§ÛŒ Ú©Ù„ pipeline Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø¯Ø§Ø¯Ù‡ Ø§Ø³Øª
"""

import argparse
import pandas as pd
from pathlib import Path
import sys
import os

# Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† Ù…Ø³ÛŒØ± Ù¾Ø±ÙˆÚ˜Ù‡ Ø¨Ù‡ PYTHONPATH
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from src.data_loader import DataLoader
from src.data_cleaner import DataCleaner
from src.eda_analyzer import EDAAnalyzer
from src.visualizer import Visualizer
from src.report_generator import ReportGenerator
from src.utils import setup_logger, load_config

def main():
    """
    ØªØ§Ø¨Ø¹ Ø§ØµÙ„ÛŒ Ø§Ø¬Ø±Ø§ÛŒ Ù¾Ø±ÙˆÚ˜Ù‡
    """
    # ØªÙ†Ø¸ÛŒÙ… logger
    logger = setup_logger('main', log_file='outputs/logs/main.log')
    logger.info("ğŸš€ Starting Data Cleaning and EDA Assistant...")
    
    # Ù¾Ø§Ø±Ø³ Ú©Ø±Ø¯Ù† Ø¢Ø±Ú¯ÙˆÙ…Ø§Ù†â€ŒÙ‡Ø§ÛŒ Ø®Ø· ÙØ±Ù…Ø§Ù†
    parser = argparse.ArgumentParser(
        description='Ø¯Ø³ØªÛŒØ§Ø± Ù‡ÙˆØ´Ù…Ù†Ø¯ Ù¾Ø§Ú©Ø³Ø§Ø²ÛŒ Ø¯Ø§Ø¯Ù‡ Ùˆ EDA',
        formatter_class=argparse.RawDescriptionHelpFormatter
    )
    
    parser.add_argument(
        '--input', '-i',
        type=str,
        required=True,
        help='Ù…Ø³ÛŒØ± ÙØ§ÛŒÙ„ ÙˆØ±ÙˆØ¯ÛŒ (CSV, Excel, JSON)'
    )
    
    parser.add_argument(
        '--output', '-o',
        type=str,
        default='outputs/reports',
        help='Ù¾ÙˆØ´Ù‡ Ø®Ø±ÙˆØ¬ÛŒ Ú¯Ø²Ø§Ø±Ø´â€ŒÙ‡Ø§'
    )
    
    parser.add_argument(
        '--config', '-c',
        type=str,
        default='config/config.yaml',
        help='Ù…Ø³ÛŒØ± ÙØ§ÛŒÙ„ ØªÙ†Ø¸ÛŒÙ…Ø§Øª'
    )
    
    parser.add_argument(
        '--skip-cleaning',
        action='store_true',
        help='Ù¾Ø±Ø´ Ø§Ø² Ù…Ø±Ø­Ù„Ù‡ Ù¾Ø§Ú©Ø³Ø§Ø²ÛŒ'
    )
    
    parser.add_argument(
        '--save-processed',
        action='store_true',
        help='Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø´Ø¯Ù‡'
    )
    
    args = parser.parse_args()
    
    try:
        # 1. Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø¯Ø§Ø¯Ù‡
        logger.info(f"ğŸ“‚ Loading data from: {args.input}")
        loader = DataLoader(args.config)
        df = loader.load_data(args.input)
        logger.info(f"âœ… Data loaded successfully: {df.shape}")
        
        # 2. Ù¾Ø§Ú©Ø³Ø§Ø²ÛŒ Ø¯Ø§Ø¯Ù‡
        if not args.skip_cleaning:
            logger.info("ğŸ§¹ Starting data cleaning...")
            cleaner = DataCleaner(df, args.config)
            df_clean, cleaning_report = cleaner.clean_all()
            logger.info(cleaner.get_cleaning_summary())
        else:
            logger.info("â­ï¸ Skipping data cleaning step")
            df_clean = df
            cleaning_report = {}
        
        # 3. Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù¾Ø§Ú©Ø³Ø§Ø²ÛŒ Ø´Ø¯Ù‡
        if args.save_processed:
            output_path = Path('data/processed')
            output_path.mkdir(parents=True, exist_ok=True)
            processed_file = output_path / f"processed_{Path(args.input).stem}.csv"
            loader.save_processed_data(df_clean, str(processed_file))
            logger.info(f"ğŸ’¾ Processed data saved to: {processed_file}")
        
        # 4. ØªØ­Ù„ÛŒÙ„ EDA
        logger.info("ğŸ“Š Starting EDA analysis...")
        analyzer = EDAAnalyzer(df_clean)
        analysis_results = analyzer.generate_full_report()
        
        # Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† Ø¯ÛŒØªØ§ÙØ±ÛŒÙ… Ø¨Ù‡ Ù†ØªØ§ÛŒØ¬ Ø¨Ø±Ø§ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø¯Ø± Ú¯Ø²Ø§Ø±Ø´
        analysis_results['df'] = df_clean
        
        # Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† Ø¨ÛŒÙ†Ø´â€ŒÙ‡Ø§
        insights = analyzer.get_insights()
        analysis_results['insights'] = insights
        
        logger.info("âœ… EDA analysis completed")
        
        # 5. Ù…ØµÙˆØ±Ø³Ø§Ø²ÛŒ
        logger.info("ğŸ¨ Creating visualizations...")
        visualizer = Visualizer(df_clean, args.config)
        
        # Ø§ÛŒØ¬Ø§Ø¯ Ø¯Ø§Ø´Ø¨ÙˆØ±Ø¯
        figures = visualizer.create_dashboard()
        
        # Ø°Ø®ÛŒØ±Ù‡ Ù†Ù…ÙˆØ¯Ø§Ø±Ù‡Ø§
        for name, fig in figures.items():
            visualizer.save_figure(fig, name)
        
        logger.info(f"âœ… Created {len(figures)} visualizations")
        
        # 6. ØªÙˆÙ„ÛŒØ¯ Ú¯Ø²Ø§Ø±Ø´
        logger.info("ğŸ“„ Generating reports...")
        report_gen = ReportGenerator(analysis_results, cleaning_report)
        saved_files = report_gen.save_all_reports(args.output)
        
        logger.info("âœ… Reports generated successfully:")
        for format_type, filepath in saved_files.items():
            logger.info(f"   - {format_type}: {filepath}")
        
        # 7. Ù†Ù…Ø§ÛŒØ´ Ø®Ù„Ø§ØµÙ‡
        print("\n" + "="*60)
        print("âœ… Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø§Ù†Ø¬Ø§Ù… Ø´Ø¯!")
        print("="*60)
        print(f"ğŸ“Š ØªØ¹Ø¯Ø§Ø¯ Ø±Ú©ÙˆØ±Ø¯Ù‡Ø§: {df_clean.shape[0]:,}")
        print(f"ğŸ“ ØªØ¹Ø¯Ø§Ø¯ ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§: {df_clean.shape[1]}")
        print(f"ğŸ“ Ú¯Ø²Ø§Ø±Ø´â€ŒÙ‡Ø§ Ø¯Ø± Ù¾ÙˆØ´Ù‡ {args.output} Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯Ù†Ø¯")
        print("="*60)
        
    except Exception as e:
        logger.error(f"âŒ Error in main pipeline: {e}")
        print(f"\nâŒ Ø®Ø·Ø§ Ø¯Ø± Ø§Ø¬Ø±Ø§ÛŒ Ø¨Ø±Ù†Ø§Ù…Ù‡: {e}")
        sys.exit(1)

if __name__ == "__main__":
    main()